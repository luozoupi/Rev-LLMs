#!/usr/bin/env python3
"""
Test Device Fixes
================

Test script to verify that all device synchronization issues are resolved
in the comprehensive benchmark.
"""

import torch
import sys
import os
import logging
from pathlib import Path

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Add current directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_device_aware_glue_benchmark():
    """Test the device-aware GLUE benchmark wrapper"""
    logger.info("Testing device-aware GLUE benchmark...")
    
    try:
        from device_aware_glue_benchmark import DeviceAwareGLUEBenchmark
        
        # Test initialization
        benchmark = DeviceAwareGLUEBenchmark(force_device='cpu')
        logger.info("‚úì Device-aware GLUE benchmark initialized successfully")
        
        # Test safe tensor conversion
        test_list = [1, 2, 3, 4, 5]
        result = benchmark._safe_tensor_to_device(test_list, 'cpu')
        assert isinstance(result, torch.Tensor), "Should convert list to tensor"
        logger.info("‚úì Safe tensor conversion works")
        
        return True
        
    except Exception as e:
        logger.error(f"‚úó Device-aware GLUE benchmark test failed: {e}")
        return False

def test_comprehensive_benchmark_init():
    """Test comprehensive benchmark initialization"""
    logger.info("Testing comprehensive benchmark initialization...")
    
    try:
        from comprehensive_qwen3_dizo_benchmark import BenchmarkConfig, ComprehensiveQwen3DiZOBenchmark
        
        # Test config creation
        config = BenchmarkConfig(scale='small')
        logger.info("‚úì Benchmark config created successfully")
        
        # Test benchmark initialization with CPU device
        benchmark = ComprehensiveQwen3DiZOBenchmark(config, device='cpu')
        logger.info("‚úì Comprehensive benchmark initialized successfully")
        
        return True
        
    except Exception as e:
        logger.error(f"‚úó Comprehensive benchmark initialization failed: {e}")
        return False

def test_model_creation():
    """Test model creation with device handling"""
    logger.info("Testing model creation...")
    
    try:
        from comprehensive_qwen3_dizo_benchmark import BenchmarkConfig, ModelTrainer
        
        config = BenchmarkConfig(scale='small')
        trainer = ModelTrainer(config, device='cpu')
        
        # Test model creation
        models = trainer.create_models()
        
        if models:
            logger.info(f"‚úì Created {len(models)} models: {list(models.keys())}")
            
            # Verify all models are on CPU
            for name, model in models.items():
                try:
                    model_device = next(model.parameters()).device
                    assert str(model_device) == 'cpu', f"Model {name} should be on CPU, got {model_device}"
                    logger.info(f"‚úì Model {name} is correctly on CPU")
                except Exception as e:
                    logger.warning(f"Could not verify device for {name}: {e}")
            
            return True
        else:
            logger.warning("No models created, but no errors occurred")
            return True
            
    except Exception as e:
        logger.error(f"‚úó Model creation test failed: {e}")
        return False

def test_safe_benchmark_run():
    """Test a minimal benchmark run to check for device errors"""
    logger.info("Testing safe benchmark run...")
    
    try:
        from comprehensive_qwen3_dizo_benchmark import BenchmarkConfig, ComprehensiveQwen3DiZOBenchmark
        
        # Create minimal config
        config = BenchmarkConfig(scale='small')
        config.num_epochs = 1  # Very short training
        config.train_size = 10  # Very small dataset
        config.eval_size = 5
        
        # Initialize benchmark
        benchmark = ComprehensiveQwen3DiZOBenchmark(config, device='cpu')
        
        # Run minimal benchmark
        results = benchmark.run_full_benchmark(tasks=['sst2'], compare_dizo=False)
        
        if results:
            logger.info("‚úì Benchmark run completed without device errors")
            
            # Check for device-related errors in results
            device_errors = []
            
            def check_for_device_errors(obj, path=""):
                if isinstance(obj, dict):
                    for k, v in obj.items():
                        if isinstance(v, str) and ('device' in v.lower() or 'cuda' in v.lower() or 'cpu' in v.lower()):
                            if 'error' in k.lower() or 'fail' in str(v).lower():
                                device_errors.append(f"{path}.{k}: {v}")
                        elif isinstance(v, (dict, list)):
                            check_for_device_errors(v, f"{path}.{k}")
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        check_for_device_errors(item, f"{path}[{i}]")
            
            check_for_device_errors(results)
            
            if device_errors:
                logger.warning(f"Found potential device-related errors: {device_errors}")
            else:
                logger.info("‚úì No device-related errors found in results")
            
            return True
        else:
            logger.warning("Benchmark returned empty results")
            return False
            
    except Exception as e:
        if 'device' in str(e).lower() or 'cuda' in str(e).lower():
            logger.error(f"‚úó Device-related error in benchmark run: {e}")
            return False
        else:
            logger.warning(f"Non-device error in benchmark run: {e}")
            return True  # Non-device errors are acceptable for this test

def test_device_synchronization():
    """Test device synchronization scenarios"""
    logger.info("Testing device synchronization scenarios...")
    
    try:
        # Test tensor operations that previously caused errors
        
        # Test 1: Mixed device tensors (the main error scenario)
        cpu_tensor = torch.tensor([1, 2, 3], device='cpu')
        
        # Simulate the problematic index_select operation
        indices = torch.tensor([0, 1], device='cpu')
        result = torch.index_select(cpu_tensor, 0, indices)
        
        assert result.device == cpu_tensor.device, "Result should be on same device as input"
        logger.info("‚úì index_select operation works correctly")
        
        # Test 2: Tensor conversion scenarios
        test_list = [1, 2, 3, 4, 5]
        tensor = torch.tensor(test_list, device='cpu')
        moved_tensor = tensor.to('cpu')  # Should not fail
        
        assert moved_tensor.device.type == 'cpu', "Tensor should be on CPU"
        logger.info("‚úì Tensor device conversion works correctly")
        
        # Test 3: Batch processing simulation
        batch_tensors = [torch.randn(10, device='cpu') for _ in range(3)]
        stacked = torch.stack(batch_tensors)
        
        assert stacked.device.type == 'cpu', "Stacked tensor should be on CPU"
        logger.info("‚úì Batch tensor operations work correctly")
        
        return True
        
    except Exception as e:
        logger.error(f"‚úó Device synchronization test failed: {e}")
        return False

def main():
    """Run all device fix tests"""
    logger.info("üß™ Starting device fix tests...")
    
    tests = [
        ("Device-aware GLUE benchmark", test_device_aware_glue_benchmark),
        ("Comprehensive benchmark init", test_comprehensive_benchmark_init),
        ("Model creation", test_model_creation),
        ("Device synchronization", test_device_synchronization),
        ("Safe benchmark run", test_safe_benchmark_run),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\n--- Testing: {test_name} ---")
        try:
            if test_func():
                logger.info(f"‚úÖ {test_name}: PASSED")
                passed += 1
            else:
                logger.error(f"‚ùå {test_name}: FAILED")
        except Exception as e:
            logger.error(f"‚ùå {test_name}: FAILED with exception: {e}")
    
    logger.info(f"\nüìä Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        logger.info("üéâ All device fix tests passed! The device synchronization issues should be resolved.")
        return True
    else:
        logger.warning(f"‚ö†Ô∏è {total - passed} tests failed. Some device issues may remain.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)